# this is an example configuration file for a topic
# see config.yaml for global configuration options
name: "Demo"
description: "Demo topic, best demo of all time"

# Which feeds to process for this topic
feeds:
  - "cond-mat"
  - "nature"
  - "science"
  - "nat-mat"
  - "nat-nanotech"
  - "nat-phys"
  - "nat-chem"
  - "nat-ener"
  - "nat-catal"
  - "nat-chem-eng"
  - "nat-rev-phys"
  - "pnas"
  - "joule"
  - "prb"
  - "prl"
  - "prx"
  - "pr_res"
  - "nano-lett"
  - "acs-nano"
  - "acs-en-lett"
  - "en-env-sci"
  - "science-adv"
  - "sci-rep"
  - "nat-comm"
  - "comm-phys"
  - "comm-mater"
  - "scipost"
  - "small"
  - "adv-mater"
  - "adv-sci"
  - "adv-func-mater"
  - "adv-phys-res"
  - "national-sci-rev"
  - "npj-2d-mater"
  - "npj-comp-mater"
  - "npj-qmat"

# Regex filter
filter:
  pattern: '(foo.*)|\
            (.*bar)'
  fields: ["title", "summary"]

# Ranking configuration
ranking: 
  query: >   # Natural-language ranking query used for sentence-transformers similarity
    foobar, barfoo

  # Optional additional negative phrases to downweight (list may be empty)
  negative_queries: [erratum, correction, reply, corrigendum]

  # Preferred authors. Names in this list get a ranking boost. Order: First name (or initial), Last name.
  preferred_authors: [Example Eric]
  priority_author_boost: 0.2

  # Sentence-Transformers model used for ranking (can be overridden per topic)
  model: "all-MiniLM-L6-v2"

# Abstract fetch configuration
abstract_fetch:
  enabled: true
  rank_threshold: 0.2 # this overrides the global rank_threshold in config.yaml. Should be smaller than score_cutoff

llm_summary: # to be discontinued in future major versions. Paper-qa summarization much more useful.
  enabled: true
  prompt: > # Uses ranking_query from the ranking configuration to assess topical relevance
    You are a domain expert on foooooooo and baaaaaar.
    Prefer clear methodological advances and results with high potential impact.
    Be concise and expert-focused. Keep text concise and information-dense.
    Avoid using superlatives and other over-the-top language.
    CRITICAL: Return ONLY valid JSON with the exact structure specified.
    No markdown formatting, no explanations, no text before or after the JSON object.
    Required JSON structure:
    {
      "summary": "Brief technical summary of the paper",
      "topical_relevance": "Assessment of relevance to: {ranking_query}, in one sentence",
      "novelty_impact": "Evaluation of novelty and potential impact"
    }  
  # Cutoffs: strongest cutoff applies (the one returning the fewest entries)
  # score_cutoff: minimum cosine similarity (0.0â€“1.0)
  score_cutoff: 0.3
  top_n: 10

# Output configuration
output:
  filename: "results_demo.html"
  filename_ranked: "results_demo_ranked.html"
  filename_summary: "results_demo_summary.html"
  archive: true # archive the output file to the "matched_entries_history.db" database

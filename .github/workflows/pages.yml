name: Build and Deploy

on:
  workflow_dispatch:  # Manual trigger
  schedule:
    - cron: '0 4 * * *'  # 04:00 UTC daily

permissions:
  contents: write # Required for uploading DB snapshots to data branch
  pages: write
  id-token: write

# Prevent concurrent runs from corrupting the SQLite database
concurrency:
  group: pages-db
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0    # ensure all branches/refs available

      # Cache the seen_entries.db to persist article tracking between runs
      - name: Restore database cache
        uses: actions/cache@v3
        with:
          path: assets/seen_entries.db
          key: seen-db-${{ github.run_id }}     # Unique cache key per run
          restore-keys: |
            seen-db-                            # Fallback to most recent cache

      # Create assets dir & empty DB if missing (no sqlite3 CLI dependency)
      - name: Ensure assets dir & empty DB if missing
        run: |
          set -euo pipefail
          mkdir -p assets
          python -c "import sqlite3, os; p = 'assets/seen_entries.db'; con = sqlite3.connect(p) if not os.path.exists(p) else None; con.execute('PRAGMA user_version=1;') if con else None; con.close() if con else None"

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - run: pip install -r requirements.txt

      # Run the main RSS parser
      - run: python rssparser.py --no-upload
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      # DATABASE SNAPSHOTTING STEP
      - name: Snapshot DBs to data branch with retention (worktree)
        env:
          KEEP_SNAPSHOTS: "30"
          SNAP_DIR: "assets/db_history"
          DB_HISTORY: "assets/matched_entries_history.db"
          DB_SEEN: "assets/seen_entries.db"
        run: |
          set -euo pipefail

          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git fetch origin --prune

          # Ensure remote data branch exists; create from current HEAD if missing
          if ! git ls-remote --exit-code --heads origin data >/dev/null 2>&1; then
            git branch -f data HEAD
            git push -u origin data || true
          fi

          # Worktree on data branch (create/reset local branch to origin/data)
          WT=/tmp/data-wt
          mkdir -p "$WT"
          git worktree add -B data "$WT" origin/data
          cleanup() { git worktree remove -f "$WT" || true; }
          trap cleanup EXIT

          pushd "$WT" >/dev/null
            mkdir -p "$SNAP_DIR" assets
            TS="$(date -u +%Y%m%dT%H%M%SZ)"

            snapshot_one() {
              local src="$1"; local stem="$2"
              if [ -f "$GITHUB_WORKSPACE/$src" ]; then
                local snap="$SNAP_DIR/${stem}_${TS}.db"
                cp "$GITHUB_WORKSPACE/$src" "$snap"
                cp "$GITHUB_WORKSPACE/$src" "assets/${stem}.latest.db"
                git add -f "$snap" "assets/${stem}.latest.db"
              else
                echo "Skip: $src not found"
              fi
            }

            # Both DBs
            snapshot_one "$DB_HISTORY" "matched_entries_history"
            snapshot_one "$DB_SEEN" "seen_entries"

            # Retention per DB
            retain() {
              local stem="$1"
              mapfile -t FILES < <(ls -1t "$SNAP_DIR"/${stem}_*.db 2>/dev/null || true)
              if [ "${#FILES[@]}" -gt "${KEEP_SNAPSHOTS}" ]; then
                for f in "${FILES[@]:${KEEP_SNAPSHOTS}}"; do rm -f "$f"; done
              fi
            }
            retain "matched_entries_history"
            retain "seen_entries"

            # Stage deletions from retention
            git add -A "$SNAP_DIR" || true

            if ! git diff --cached --quiet; then
              git commit -m "Snapshot DBs @ ${TS} [skip ci]"
              git push origin data
            else
              echo "No changes to commit."
            fi
          popd >/dev/null

      # Prepare files for GitHub Pages deployment
      - name: Prepare site
        run: |
          mkdir site
          cp -r archive site/ || true
          cp *.html site/ || true

      - uses: actions/upload-pages-artifact@v3
        with:
          path: ./site

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - id: deployment
        uses: actions/deploy-pages@v4
